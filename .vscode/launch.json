{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python 调试程序: 包含参数的当前文件",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": "${command:pickArgs}"
        },
        {
            "env": {
                "PYTHONPATH": "${workspaceFolder}${pathSeparator}${env:PYTHONPATH}",
                "CUDA_VISIBLE_DEVICES": "1,2"
            },
            "cwd": "${fileDirname}",
            "name": "Python 调试程序: inference",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/rtxrtx/envs/LLMCL/bin/accelerate",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "launch",
                "--main_process_port",
                "25554",
                "--num_processes",
                "2",
                "${file}",
                "--dataset_names",
                "C-STANCE,FOMC,MeetingBank,ScienceQA,NumGLUE-cm,20Minuten",
                "--model_name",
                "/home/rtxrtx/PLLM/llama-2-7b-chat-hf",
                "--adapter_checkpoint_dir",
                "/home/rtxrtx/github/LLMCL/outputs/models/PP/PP_prompt_checkpoint_20Minuten",
                "--output_dir",
                "./outputs/inference",
            ]
        },
        {
            "env": {
                "PYTHONPATH": "${workspaceFolder}${pathSeparator}${env:PYTHONPATH}"
            },
            "cwd": "${fileDirname}",
            "name": "Python debug: deepspeed train",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/rtxrtx/envs/LLMCL/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--include=localhost:0",
                "--master_port=25555",
                "${file}",
                "--data_path",
                "/home/rtxrtx/github/LLMCL/data_files",
                "--dataset_name",
                "C-STANCE,FOMC,MeetingBank,ScienceQA,NumGLUE-cm,20Minuten,medmcqa,jecqa",
                "--model_name_or_path",
                "/home/rtxrtx/PLLM/llama-2-7b-chat-hf",
                "--per_device_train_batch_size",
                "2",
                "--per_device_eval_batch_size",
                "2",
                "--gradient_accumulation_steps",
                "2",
                "--max_prompt_len",
                "512",
                "--max_ans_len",
                "512",
                "--learning_rate",
                "1e-4",
                "--weight_decay",
                "0.",
                "--num_train_epochs",
                "5",
                "--warmup_ratio",
                "0.2",
                "--seed",
                "42",
                "--adapter",
                "prompt",
                // "--num_virtual_tokens",
                // "0",
                "--cl_method",
                "PP",
                // "--resume_from_checkpoint",
                // "./outputs/models/$CL_METHOD",
                "--output_dir",
                "./outputs/models/PP",
            ]
        },
    ]
}